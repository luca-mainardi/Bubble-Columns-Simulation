{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT_32x6mm-airwater-eps35.csv: 481.0\n",
      "FT_32x6mm-airwater-eps25.csv: 481.0\n",
      "FT_32x4mm-airwater-eps15.csv: 275.0\n",
      "FT_32x4mm-airwater-eps25.csv: 454.0\n",
      "FT_32x4mm-airwater-eps35.csv: 481.0\n",
      "FT_32x6mm-airwater-eps15.csv: 296.0\n"
     ]
    }
   ],
   "source": [
    "# get length of all csv files in a directory\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def get_csv_length(file):\n",
    "    df = pd.read_csv(f'../data/csv/{file}')\n",
    "    return len(df)/32\n",
    "    \n",
    "directory = \"../data/csv\"\n",
    "files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "for file in files:\n",
    "    print(f'{file}: {get_csv_length(file)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/pickles_csv/FT_32x4mm-airwater-eps15.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm, trange\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# from scripts.models import EGNN_vel, MSE_harmonics, Trainer\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Load the CSV file into a DataFrame\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/pickles_csv/FT_32x4mm-airwater-eps15.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the DataFrame\u001b[39;00m\n\u001b[1;32m     21\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Desktop/ATAI/Bubbles copy/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ATAI/Bubbles copy/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/ATAI/Bubbles copy/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ATAI/Bubbles copy/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/ATAI/Bubbles copy/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/pickles_csv/FT_32x4mm-airwater-eps15.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scripts.dataset import (\n",
    "    process_csv,\n",
    "    compute_box_size,\n",
    "    apply_periodic_boundary_conditions,\n",
    "    check_trajectory,\n",
    ")\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# from scripts.models import EGNN_vel, MSE_harmonics, Trainer\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"../data/pickles_csv/FT_32x4mm-airwater-eps15.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bub_num</th>\n",
       "      <th>time [s]</th>\n",
       "      <th>vel_x</th>\n",
       "      <th>vel_y</th>\n",
       "      <th>vel_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.074537</td>\n",
       "      <td>0.079467</td>\n",
       "      <td>0.138480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.111090</td>\n",
       "      <td>0.051433</td>\n",
       "      <td>0.153936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.020208</td>\n",
       "      <td>0.058066</td>\n",
       "      <td>0.060245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.013191</td>\n",
       "      <td>0.059969</td>\n",
       "      <td>0.065174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.036984</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.089404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.025277</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.185379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.034197</td>\n",
       "      <td>0.031990</td>\n",
       "      <td>0.157432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.053398</td>\n",
       "      <td>0.192336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.017664</td>\n",
       "      <td>0.171606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.054629</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.148776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.062022</td>\n",
       "      <td>-0.019311</td>\n",
       "      <td>0.147705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.053310</td>\n",
       "      <td>-0.020403</td>\n",
       "      <td>0.129767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.043817</td>\n",
       "      <td>-0.027958</td>\n",
       "      <td>0.181658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.021712</td>\n",
       "      <td>-0.022105</td>\n",
       "      <td>0.176693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.052374</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.194556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.014853</td>\n",
       "      <td>0.015246</td>\n",
       "      <td>0.207401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.044862</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>0.195659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>0.073831</td>\n",
       "      <td>0.140320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.002329</td>\n",
       "      <td>0.028069</td>\n",
       "      <td>0.134742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.034820</td>\n",
       "      <td>-0.075104</td>\n",
       "      <td>0.160081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bub_num  time [s]     vel_x     vel_y     vel_z\n",
       "0          0      0.20 -0.074537  0.079467  0.138480\n",
       "32         0      0.21 -0.111090  0.051433  0.153936\n",
       "64         0      0.22 -0.020208  0.058066  0.060245\n",
       "96         0      0.23 -0.013191  0.059969  0.065174\n",
       "128        0      0.24  0.036984  0.017956  0.089404\n",
       "160        0      0.25  0.025277  0.005854  0.185379\n",
       "192        0      0.26 -0.034197  0.031990  0.157432\n",
       "224        0      0.27 -0.003539  0.053398  0.192336\n",
       "256        0      0.28  0.001879  0.017664  0.171606\n",
       "288        0      0.29 -0.054629  0.015735  0.148776\n",
       "320        0      0.30 -0.062022 -0.019311  0.147705\n",
       "352        0      0.31 -0.053310 -0.020403  0.129767\n",
       "384        0      0.32 -0.043817 -0.027958  0.181658\n",
       "416        0      0.33  0.021712 -0.022105  0.176693\n",
       "448        0      0.34  0.052374  0.001148  0.194556\n",
       "480        0      0.35 -0.014853  0.015246  0.207401\n",
       "512        0      0.36 -0.044862  0.040901  0.195659\n",
       "544        0      0.37 -0.008018  0.073831  0.140320\n",
       "576        0      0.38 -0.002329  0.028069  0.134742\n",
       "608        0      0.39 -0.034820 -0.075104  0.160081"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df[\"bub_num\"] == 0]\n",
    "df_filtered = df_filtered[[\"bub_num\", \"time [s]\", \"vel_x\", \"vel_y\", \"vel_z\"]]\n",
    "df_filtered.iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  FT_32x6mm-airwater-eps35.csv\n",
      "Box size:  0.021786030258038356\n",
      "Processing file:  FT_32x6mm-airwater-eps25.csv\n",
      "Box size:  0.024371791141518228\n",
      "Processing file:  FT_32x4mm-airwater-eps15.csv\n",
      "Box size:  0.019263969051043647\n",
      "Processing file:  FT_32x4mm-airwater-eps25.csv\n",
      "Box size:  0.016247860761012152\n",
      "Processing file:  FT_32x4mm-airwater-eps35.csv\n",
      "Box size:  0.014524020172025571\n",
      "Processing file:  FT_32x6mm-airwater-eps15.csv\n",
      "Box size:  0.028895953576565468\n"
     ]
    }
   ],
   "source": [
    "min_orb_values, max_orb_values = process_csv(\"../data/pickles_csv/\", \"../data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BubbleDataset(InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        raw_data_path,\n",
    "        processed_data_path,\n",
    "        root=None,\n",
    "        processed_file_name=\"BubbleDataset_1.pt\",\n",
    "        num_bubbles=32,\n",
    "        min_orb_values=None,\n",
    "        max_orb_values=None,\n",
    "    ):\n",
    "        self.raw_data_path = raw_data_path\n",
    "        self.processed_data_path = processed_data_path\n",
    "        self.processed_file_name = processed_file_name\n",
    "        self.num_bubbles = num_bubbles\n",
    "        if min_orb_values is not None:\n",
    "            self.min_orb_values = torch.tensor(min_orb_values, dtype=torch.float)\n",
    "        else:\n",
    "            self.min_orb_values = None\n",
    "        if max_orb_values is not None:\n",
    "            self.max_orb_values = torch.tensor(max_orb_values, dtype=torch.float)\n",
    "        else:\n",
    "            self.max_orb_values = None\n",
    "        super(BubbleDataset, self).__init__(root)\n",
    "\n",
    "        # Define processed file path\n",
    "        processed_file_path = self.processed_paths[0]\n",
    "\n",
    "        # Check if the processed file exists; if not, call process() to generate it\n",
    "        if not os.path.exists(self.processed_paths[0]):\n",
    "            print(\n",
    "                f\"Processed file not found at {self.processed_paths[0]}. Generating...\"\n",
    "            )\n",
    "            self.process()\n",
    "        else:\n",
    "            # Load the processed data\n",
    "            self.data, self.slices = torch.load(processed_file_path)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [fn for fn in os.listdir(self.raw_data_path)]\n",
    "\n",
    "    @property\n",
    "    def processed_paths(self):\n",
    "        return [os.path.join(self.processed_data_path, self.processed_file_name)]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        total_time_steps = 0\n",
    "        for idx, raw_path in enumerate(self.raw_file_names):\n",
    "\n",
    "            # Load trajectory from pickle file\n",
    "            trajectory = pd.read_pickle(self.raw_data_path + raw_path)\n",
    "\n",
    "            # Count the number of unique time steps\n",
    "            num_time_steps = len(trajectory[\"time [s]\"].unique())\n",
    "            total_time_steps += (\n",
    "                num_time_steps - 1\n",
    "            )  # Subtract 1 because we need a previous and next time step\n",
    "\n",
    "        return total_time_steps\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for idx, raw_path in enumerate(self.raw_file_names):\n",
    "\n",
    "            # Load trajectory from pickle file\n",
    "            try:\n",
    "\n",
    "                trajectory = pd.read_pickle(self.raw_data_path + raw_path)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Errore nel caricamento del file {self.raw_data_path + raw_path}: {e}\"\n",
    "                )\n",
    "\n",
    "            # Ensure data is sorted by time and bubble number for correct indexing\n",
    "            trajectory = trajectory.sort_values(by=[\"time [s]\", \"bub_num\"]).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "            # Compute the scaling factor for the trajectory\n",
    "            r_bub = trajectory[\"r_bub\"].values[0]\n",
    "            eps = trajectory[\"eps\"].values[0]\n",
    "            box_size = compute_box_size(r_bub, eps, self.num_bubbles)\n",
    "\n",
    "            # Every attribute that starts with orb_ is an orbital attribute\n",
    "            # Select columns that start with \"orb_\"\n",
    "            orb_columns = [col for col in trajectory.columns if col.startswith(\"orb_\")]\n",
    "\n",
    "            time_steps = trajectory[\"time [s]\"].unique()\n",
    "\n",
    "            for i in range(len(time_steps) - 1):\n",
    "                # Get the time corresponding to the current index\n",
    "                current_time = time_steps[i]\n",
    "                next_time = time_steps[i + 1]\n",
    "\n",
    "                # Filter the data for the current and next time steps\n",
    "                current_data = trajectory[trajectory[\"time [s]\"] == current_time]\n",
    "                next_data = trajectory[trajectory[\"time [s]\"] == next_time]\n",
    "\n",
    "                # Extract the positions and velocities of the current step\n",
    "                current_pos = torch.tensor(\n",
    "                    current_data[[\"pos_x\", \"pos_y\", \"pos_z\"]].values,\n",
    "                    dtype=torch.float,\n",
    "                    requires_grad=True,\n",
    "                )\n",
    "                current_vel = torch.tensor(\n",
    "                    current_data[[\"vel_x\", \"vel_y\", \"vel_z\"]].values,\n",
    "                    dtype=torch.float,\n",
    "                    requires_grad=True,\n",
    "                )\n",
    "\n",
    "                # Extract the positions and velocities of the next step\n",
    "                next_pos = torch.tensor(\n",
    "                    next_data[[\"pos_x\", \"pos_y\", \"pos_z\"]].values, dtype=torch.float\n",
    "                )\n",
    "                next_vel = torch.tensor(\n",
    "                    next_data[[\"vel_x\", \"vel_y\", \"vel_z\"]].values,\n",
    "                    dtype=torch.float,\n",
    "                )\n",
    "\n",
    "                # Scale positions\n",
    "                current_pos = current_pos / box_size\n",
    "                next_pos = next_pos / box_size\n",
    "\n",
    "                # Check that all positions\n",
    "                assert torch.all(current_pos >= 0) and torch.all(current_pos <= 1)\n",
    "                assert torch.all(next_pos >= 0) and torch.all(next_pos <= 1)\n",
    "\n",
    "                # Convert the selected columns to a tensor\n",
    "                current_orbs = torch.tensor(\n",
    "                    current_data[orb_columns].values,\n",
    "                    dtype=torch.float,\n",
    "                )\n",
    "                next_orbs = torch.tensor(\n",
    "                    next_data[orb_columns].values, dtype=torch.float\n",
    "                )\n",
    "\n",
    "                # Normalize the orbital attributes\n",
    "                if self.min_orb_values is not None and self.max_orb_values is not None:\n",
    "\n",
    "                    current_orbs = (current_orbs - self.min_orb_values) / (\n",
    "                        self.max_orb_values - self.min_orb_values\n",
    "                    )\n",
    "\n",
    "                    next_orbs = (next_orbs - self.min_orb_values) / (\n",
    "                        self.max_orb_values - self.min_orb_values\n",
    "                    )\n",
    "                    # Check that all orbital attributes are within the range [0, 1]\n",
    "                    assert torch.all(current_orbs >= 0) and torch.all(current_orbs <= 1)\n",
    "                    assert torch.all(next_orbs >= 0) and torch.all(next_orbs <= 1)\n",
    "                else:\n",
    "                    print(\n",
    "                        \"WARNING: Min and max values for the orbital attributes are not provided. \"\n",
    "                        \"Orbital attributes are not normalized.\"\n",
    "                    )\n",
    "\n",
    "                current_orbs.requires_grad_()\n",
    "\n",
    "                # TODO add eps value\n",
    "\n",
    "                # Create edge index and edge attributes\n",
    "                edge_index = (\n",
    "                    torch.tensor(\n",
    "                        [\n",
    "                            [i, j]\n",
    "                            for i in range(self.num_bubbles)\n",
    "                            for j in range(self.num_bubbles)\n",
    "                            if i != j\n",
    "                        ],\n",
    "                        dtype=torch.long,\n",
    "                    )\n",
    "                    .t()\n",
    "                    .contiguous()\n",
    "                )\n",
    "\n",
    "                edge_attr = torch.stack(\n",
    "                    [\n",
    "                        torch.cat(\n",
    "                            (\n",
    "                                current_pos[j] - current_pos[i],\n",
    "                                current_vel[j] - current_vel[i],\n",
    "                            )\n",
    "                        )\n",
    "                        for i in range(self.num_bubbles)\n",
    "                        for j in range(self.num_bubbles)\n",
    "                        if i != j\n",
    "                    ],\n",
    "                    dim=0,\n",
    "                )\n",
    "\n",
    "                data = Data(\n",
    "                    x=(current_pos, current_vel, current_orbs),\n",
    "                    y=(next_pos, next_vel, next_orbs),\n",
    "                    edge_index=edge_index,\n",
    "                    edge_attr=edge_attr,\n",
    "                    num_nodes=self.num_bubbles,\n",
    "                )\n",
    "                data_list.append(data)\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_data_path + self.processed_file_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get(idx)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({len(self)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "/var/folders/rb/wmrnk95s19s54kfvkb8zgwcm0000gn/T/ipykernel_10893/1335299690.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(processed_file_path)\n"
     ]
    }
   ],
   "source": [
    "bubble_dataset = BubbleDataset(\n",
    "    \"../data/raw/\",\n",
    "    \"../data/processed/\",\n",
    "    root=\"../data/\",\n",
    "    processed_file_name=\"BubbleDataset_debug.pt\",\n",
    "    num_bubbles=32,\n",
    "    min_orb_values=min_orb_values,\n",
    "    max_orb_values=max_orb_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT_32x6mm-airwater-eps35.csv: 481.0 time steps\n",
      "FT_32x6mm-airwater-eps25.csv: 481.0 time steps\n",
      "FT_32x4mm-airwater-eps15.csv: 275.0 time steps\n",
      "FT_32x4mm-airwater-eps25.csv: 454.0 time steps\n",
      "FT_32x4mm-airwater-eps35.csv: 481.0 time steps\n",
      "FT_32x6mm-airwater-eps15.csv: 296.0 time steps\n",
      "Total lines in all CSV files: 2468.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "csv_directory = \"../data/pickles_csv\"\n",
    "total_lines = 0\n",
    "\n",
    "for filename in os.listdir(csv_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        with open(os.path.join(csv_directory, filename), \"r\") as file:\n",
    "            line_count = sum(1 for line in file) - 1\n",
    "            if line_count % 32 != 0:\n",
    "                print(\n",
    "                    f\"File {filename} has {line_count} lines, which is not a multiple of 32\"\n",
    "                )\n",
    "            print(f\"{filename}: {line_count/32} time steps\")\n",
    "            total_lines += line_count\n",
    "\n",
    "print(f\"Total lines in all CSV files: {total_lines/32}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.26666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lines / 32 * 0.2 / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028895953576565468"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.dataset import compute_box_size\n",
    "\n",
    "compute_box_size(0.003, 0.15, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: FT_32x6mm-airwater-eps35.csv\n",
      "Column: orb_0\n",
      "max: 0.010590417817804\t min: 0.0082845874533349\n",
      "Column: orb_1\n",
      "max: 0.0019562867934808\t min: -0.00170227462451\n",
      "Column: orb_2\n",
      "max: 0.0022501847542276\t min: -0.0028906831354665\n",
      "Column: orb_3\n",
      "max: 0.0017873784900572\t min: -0.0021125841497128\n",
      "Column: orb_4\n",
      "max: 0.0019256514430752\t min: -0.0016271965598415\n",
      "Column: orb_5\n",
      "max: 0.0026889150815153\t min: -0.002395151912125\n",
      "Column: orb_6\n",
      "max: 0.001189498639316\t min: -0.0036581170159488\n",
      "Column: orb_7\n",
      "max: 0.0023915939819514\t min: -0.0024206629774622\n",
      "Column: orb_8\n",
      "max: 0.0020228274799359\t min: -0.0016821279259392\n",
      "Column: orb_9\n",
      "max: 0.0006243575592163\t min: -0.0006865121513914\n",
      "Column: orb_10\n",
      "max: 0.0008583976574868\t min: -0.0009544511042719\n",
      "Column: orb_11\n",
      "max: 0.0008264594246529\t min: -0.0008933761387753\n",
      "Column: orb_12\n",
      "max: 0.0011307730041211\t min: -0.0009792069244518\n",
      "Column: orb_13\n",
      "max: 0.0008430471849793\t min: -0.0006872633328726\n",
      "Column: orb_14\n",
      "max: 0.0009324990963879\t min: -0.0008648949697376\n",
      "Column: orb_15\n",
      "max: 0.0006749862542171\t min: -0.0006398661933009\n",
      "File: FT_32x6mm-airwater-eps25.csv\n",
      "Column: orb_0\n",
      "max: 0.0106017389403064\t min: 0.0082110004414433\n",
      "Column: orb_1\n",
      "max: 0.0024486858971481\t min: -0.0023682780934784\n",
      "Column: orb_2\n",
      "max: 0.0031166217171168\t min: -0.003200931177153\n",
      "Column: orb_3\n",
      "max: 0.0022751317756784\t min: -0.00226492472017\n",
      "Column: orb_4\n",
      "max: 0.0020537340704551\t min: -0.0018856522757719\n",
      "Column: orb_5\n",
      "max: 0.0024310768407601\t min: -0.0026306661125443\n",
      "Column: orb_6\n",
      "max: 0.0011432436295076\t min: -0.0035240431583301\n",
      "Column: orb_7\n",
      "max: 0.0032711424158881\t min: -0.0025655111454635\n",
      "Column: orb_8\n",
      "max: 0.0019167657130422\t min: -0.0023421050690631\n",
      "Column: orb_9\n",
      "max: 0.0006372432219438\t min: -0.0007764257099015\n",
      "Column: orb_10\n",
      "max: 0.0010292117374232\t min: -0.0010074713631751\n",
      "Column: orb_11\n",
      "max: 0.0007790978314064\t min: -0.0008002629108713\n",
      "Column: orb_12\n",
      "max: 0.0012174803795652\t min: -0.0010831448456445\n",
      "Column: orb_13\n",
      "max: 0.0009410575577334\t min: -0.0007787312648241\n",
      "Column: orb_14\n",
      "max: 0.0009609736479328\t min: -0.0008977607683085\n",
      "Column: orb_15\n",
      "max: 0.0006587347498426\t min: -0.0007919280658115\n",
      "File: FT_32x4mm-airwater-eps15.csv\n",
      "Column: orb_0\n",
      "max: 0.0070815592024553\t min: 0.0062280055098946\n",
      "Column: orb_1\n",
      "max: 0.0010875239432257\t min: -0.0010202017333732\n",
      "Column: orb_2\n",
      "max: 0.0008672784944879\t min: -0.001235487327552\n",
      "Column: orb_3\n",
      "max: 0.000840011717561\t min: -0.0010122980269502\n",
      "Column: orb_4\n",
      "max: 0.0011822900649594\t min: -0.00113765719223\n",
      "Column: orb_5\n",
      "max: 0.001332053233208\t min: -0.0012832494040365\n",
      "Column: orb_6\n",
      "max: 0.0006329325874333\t min: -0.0019863970318459\n",
      "Column: orb_7\n",
      "max: 0.0012226131771302\t min: -0.001395126402871\n",
      "Column: orb_8\n",
      "max: 0.0011365342553892\t min: -0.0009430303126539\n",
      "Column: orb_9\n",
      "max: 0.0003716861673727\t min: -0.0002802934816386\n",
      "Column: orb_10\n",
      "max: 0.0004951794870845\t min: -0.0004887009873644\n",
      "Column: orb_11\n",
      "max: 0.0004455358561044\t min: -0.0003860310604316\n",
      "Column: orb_12\n",
      "max: 0.0005502132447398\t min: -0.0005875736451884\n",
      "Column: orb_13\n",
      "max: 0.0003494693849635\t min: -0.0004647077974056\n",
      "Column: orb_14\n",
      "max: 0.0005142053157205\t min: -0.0005100305635756\n",
      "Column: orb_15\n",
      "max: 0.0003533199205681\t min: -0.000330498815409\n",
      "File: FT_32x4mm-airwater-eps25.csv\n",
      "Column: orb_0\n",
      "max: 0.0070812989519129\t min: 0.0063754228645116\n",
      "Column: orb_1\n",
      "max: 0.0009117147684237\t min: -0.0008069237996183\n",
      "Column: orb_2\n",
      "max: 0.0007708754558073\t min: -0.0010011469759549\n",
      "Column: orb_3\n",
      "max: 0.0008518995343323\t min: -0.0007772376352217\n",
      "Column: orb_4\n",
      "max: 0.0009805674966408\t min: -0.0010407477065511\n",
      "Column: orb_5\n",
      "max: 0.0013471393397617\t min: -0.0012506940745373\n",
      "Column: orb_6\n",
      "max: 0.0008356435368825\t min: -0.0019081718657611\n",
      "Column: orb_7\n",
      "max: 0.0013283504995669\t min: -0.0012776095786238\n",
      "Column: orb_8\n",
      "max: 0.0009866802442476\t min: -0.0010331513383854\n",
      "Column: orb_9\n",
      "max: 0.0003214219896328\t min: -0.0003592959828877\n",
      "Column: orb_10\n",
      "max: 0.0004239079897894\t min: -0.0004179095935307\n",
      "Column: orb_11\n",
      "max: 0.0004079471196512\t min: -0.0003903121221231\n",
      "Column: orb_12\n",
      "max: 0.0005117629917982\t min: -0.0005013990797836\n",
      "Column: orb_13\n",
      "max: 0.0003396013383417\t min: -0.0004395168650231\n",
      "Column: orb_14\n",
      "max: 0.0004409156037709\t min: -0.0004057275711922\n",
      "Column: orb_15\n",
      "max: 0.0003366642192559\t min: -0.0003453900761465\n",
      "File: FT_32x4mm-airwater-eps35.csv\n",
      "Column: orb_0\n",
      "max: 0.007082647306731\t min: 0.0065243150827683\n",
      "Column: orb_1\n",
      "max: 0.0006088819590493\t min: -0.0006778775384084\n",
      "Column: orb_2\n",
      "max: 0.0005963705585133\t min: -0.0009285876240103\n",
      "Column: orb_3\n",
      "max: 0.0006297661257673\t min: -0.0006869217346605\n",
      "Column: orb_4\n",
      "max: 0.0009166786548099\t min: -0.0008798483779889\n",
      "Column: orb_5\n",
      "max: 0.0011291628717863\t min: -0.0012537104984683\n",
      "Column: orb_6\n",
      "max: 0.0008250150609115\t min: -0.0017206766641728\n",
      "Column: orb_7\n",
      "max: 0.0010871664770228\t min: -0.001203119057213\n",
      "Column: orb_8\n",
      "max: 0.0009360045377254\t min: -0.0008647694901972\n",
      "Column: orb_9\n",
      "max: 0.0003358900127173\t min: -0.0002875592448679\n",
      "Column: orb_10\n",
      "max: 0.0003551760699846\t min: -0.0003288148422785\n",
      "Column: orb_11\n",
      "max: 0.0003511507358521\t min: -0.0003183787549281\n",
      "Column: orb_12\n",
      "max: 0.0004157184438928\t min: -0.0004443404355368\n",
      "Column: orb_13\n",
      "max: 0.0003054334597584\t min: -0.0002983506519329\n",
      "Column: orb_14\n",
      "max: 0.0003216560467533\t min: -0.0003308473480752\n",
      "Column: orb_15\n",
      "max: 0.0003524233637249\t min: -0.0003620493931957\n",
      "File: FT_32x6mm-airwater-eps15.csv\n",
      "Column: orb_0\n",
      "max: 3.658619064663681\t min: -47.218897790481854\n",
      "Column: orb_1\n",
      "max: 46.762980132306275\t min: -2.6182308847347593\n",
      "Column: orb_2\n",
      "max: 5.59800412267112\t min: -55.80035909235409\n",
      "Column: orb_3\n",
      "max: 0.0027158963070611\t min: -27.593870161935495\n",
      "Column: orb_4\n",
      "max: 5.933239441738356\t min: -35.18814644464157\n",
      "Column: orb_5\n",
      "max: 68.59874835061765\t min: -5.660121986359448\n",
      "Column: orb_6\n",
      "max: 5.573637002766936\t min: -26.10290852279256\n",
      "Column: orb_7\n",
      "max: 0.0024500687976181\t min: -37.28707266381154\n",
      "Column: orb_8\n",
      "max: 13.872396808794202\t min: -0.5252664465098789\n",
      "Column: orb_9\n",
      "max: 7.797202753735582\t min: -0.2329481705031091\n",
      "Column: orb_10\n",
      "max: 7.123609884258175\t min: -55.7252356053672\n",
      "Column: orb_11\n",
      "max: 57.18988606491932\t min: -6.1120010938945555\n",
      "Column: orb_12\n",
      "max: 8.953032676953383\t min: -0.0050244301572592\n",
      "Column: orb_13\n",
      "max: 0.000985390149261\t min: -25.580654849451207\n",
      "Column: orb_14\n",
      "max: 25.153045070055843\t min: -1.1271361911867293\n",
      "Column: orb_15\n",
      "max: 20.84657943062404\t min: -0.0006513137969199\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"../data/csv\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(f\"../data/csv/{file}\")\n",
    "        # Get max and min velocity\n",
    "        max_vel_x = df[\"vel_x\"].max()\n",
    "        min_vel_x = df[\"vel_x\"].min()\n",
    "        max_vel_y = df[\"vel_y\"].max()\n",
    "        min_vel_y = df[\"vel_y\"].min()\n",
    "        max_vel_z = df[\"vel_z\"].max()\n",
    "        min_vel_z = df[\"vel_z\"].min()\n",
    "\n",
    "        # print(\n",
    "        #     f\"max_vel_x: {max_vel_x}\\t min_vel_x: {min_vel_x}\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"max_vel_y: {max_vel_y}\\t min_vel_y: {min_vel_y}\\n \"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"max_vel_z: {max_vel_z}\\t min_vel_z: {min_vel_z}\"\n",
    "        # )\n",
    "        print(f\"File: {file}\")\n",
    "        orb_columns = [col for col in df.columns if col.startswith(\"orb_\")][:16]\n",
    "\n",
    "        for col in orb_columns:\n",
    "            # Count the number of lines out of range [-1, 1], and print index\n",
    "            # out_of_range = df[(df[col] < -1) | (df[col] > 1)]\n",
    "            # if len(out_of_range) > 0:\n",
    "            #     print(f\"Column: {col}\")\n",
    "            #     print(out_of_range.index)\n",
    "            #     print(\"\\n\")\n",
    "            # Find min and max values\n",
    "            max_value = df[col].max()\n",
    "            min_value = df[col].min()\n",
    "            print(f\"Column: {col}\")\n",
    "            print(f\"max: {max_value}\\t min: {min_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>sim</th>\n",
       "      <th>bub_num</th>\n",
       "      <th>time [s]</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pos_z</th>\n",
       "      <th>vel_x</th>\n",
       "      <th>vel_y</th>\n",
       "      <th>...</th>\n",
       "      <th>orb_215</th>\n",
       "      <th>orb_216</th>\n",
       "      <th>orb_217</th>\n",
       "      <th>orb_218</th>\n",
       "      <th>orb_219</th>\n",
       "      <th>orb_220</th>\n",
       "      <th>orb_221</th>\n",
       "      <th>orb_222</th>\n",
       "      <th>orb_223</th>\n",
       "      <th>orb_224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, id, sim, bub_num, time [s], pos_x, pos_y, pos_z, vel_x, vel_y, vel_z, l_max, orb_0, orb_1, orb_2, orb_3, orb_4, orb_5, orb_6, orb_7, orb_8, orb_9, orb_10, orb_11, orb_12, orb_13, orb_14, orb_15, orb_16, orb_17, orb_18, orb_19, orb_20, orb_21, orb_22, orb_23, orb_24, orb_25, orb_26, orb_27, orb_28, orb_29, orb_30, orb_31, orb_32, orb_33, orb_34, orb_35, orb_36, orb_37, orb_38, orb_39, orb_40, orb_41, orb_42, orb_43, orb_44, orb_45, orb_46, orb_47, orb_48, orb_49, orb_50, orb_51, orb_52, orb_53, orb_54, orb_55, orb_56, orb_57, orb_58, orb_59, orb_60, orb_61, orb_62, orb_63, orb_64, orb_65, orb_66, orb_67, orb_68, orb_69, orb_70, orb_71, orb_72, orb_73, orb_74, orb_75, orb_76, orb_77, orb_78, orb_79, orb_80, orb_81, orb_82, orb_83, orb_84, orb_85, orb_86, orb_87, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 237 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/csv/FT_32x6mm-airwater-eps15.csv\")\n",
    "\n",
    "\n",
    "df_filtered = df[df[\"orb_0\"] < 0]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered[\"orb_0\"] > 1]\n",
    "df_filtered.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
